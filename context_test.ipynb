{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e9e7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nanobot'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnanobot\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryStore\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnanobot\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mskills\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SkillsLoader\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mContextBuilder\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nanobot'"
     ]
    }
   ],
   "source": [
    "\"\"\"Context builder for assembling agent prompts.\"\"\"\n",
    "\n",
    "import base64\n",
    "import mimetypes\n",
    "import platform\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import json\n",
    "from memory import MemoryStore\n",
    "from skills import SkillsLoader\n",
    "\n",
    "\n",
    "class ContextBuilder:\n",
    "    \"\"\"\n",
    "    Builds the context (system prompt + messages) for the agent.\n",
    "    \n",
    "    Assembles bootstrap files, memory, skills, and conversation history\n",
    "    into a coherent prompt for the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    BOOTSTRAP_FILES = [\"AGENTS.md\", \"SOUL.md\", \"USER.md\", \"TOOLS.md\", \"IDENTITY.md\"]\n",
    "    \n",
    "    def __init__(self, workspace: Path):\n",
    "        self.workspace = workspace\n",
    "        self.memory = MemoryStore(workspace)\n",
    "        self.skills = SkillsLoader(workspace)\n",
    "    \n",
    "    def build_system_prompt(self, skill_names: list[str] | None = None) -> str:\n",
    "        \"\"\"\n",
    "        Build the system prompt from bootstrap files, memory, and skills.\n",
    "        \n",
    "        Args:\n",
    "            skill_names: Optional list of skills to include.\n",
    "        \n",
    "        Returns:\n",
    "            Complete system prompt.\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # Core identity\n",
    "        parts.append(self._get_identity())\n",
    "        \n",
    "        # Bootstrap files\n",
    "        bootstrap = self._load_bootstrap_files()\n",
    "        if bootstrap:\n",
    "            parts.append(bootstrap)\n",
    "        \n",
    "        # Memory context\n",
    "        memory = self.memory.get_memory_context()\n",
    "        if memory:\n",
    "            parts.append(f\"# Memory\\n\\n{memory}\")\n",
    "        \n",
    "        # Skills - progressive loading\n",
    "        # 1. Always-loaded skills: include full content\n",
    "        always_skills = self.skills.get_always_skills()\n",
    "        if always_skills:\n",
    "            always_content = self.skills.load_skills_for_context(always_skills)\n",
    "            if always_content:\n",
    "                parts.append(f\"# Active Skills\\n\\n{always_content}\")\n",
    "        \n",
    "        # 2. Available skills: only show summary (agent uses read_file to load)\n",
    "        skills_summary = self.skills.build_skills_summary()\n",
    "        if skills_summary:\n",
    "            parts.append(f\"\"\"# Skills\n",
    "\n",
    "The following skills extend your capabilities. To use a skill, read its SKILL.md file using the read_file tool.\n",
    "Skills with available=\"false\" need dependencies installed first - you can try installing them with apt/brew.\n",
    "\n",
    "{skills_summary}\"\"\")\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(parts)\n",
    "    \n",
    "    def _get_identity(self) -> str:\n",
    "        \"\"\"Get the core identity section.\"\"\"\n",
    "        from datetime import datetime\n",
    "        import time as _time\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M (%A)\")\n",
    "        tz = _time.strftime(\"%Z\") or \"UTC\"\n",
    "        workspace_path = str(self.workspace.expanduser().resolve())\n",
    "        system = platform.system()\n",
    "        runtime = f\"{'macOS' if system == 'Darwin' else system} {platform.machine()}, Python {platform.python_version()}\"\n",
    "        \n",
    "        return f\"\"\"# nanobot ðŸˆ\n",
    "\n",
    "You are nanobot, a helpful AI assistant. \n",
    "\n",
    "## Current Time\n",
    "{now} ({tz})\n",
    "\n",
    "## Runtime\n",
    "{runtime}\n",
    "\n",
    "## Workspace\n",
    "Your workspace is at: {workspace_path}\n",
    "- Long-term memory: {workspace_path}/memory/MEMORY.md\n",
    "- History log: {workspace_path}/memory/HISTORY.md (grep-searchable)\n",
    "- Custom skills: {workspace_path}/skills/{{skill-name}}/SKILL.md\n",
    "\n",
    "Reply directly with text for conversations. Only use the 'message' tool to send to a specific chat channel.\n",
    "\n",
    "## Tool Call Guidelines\n",
    "- Before calling tools, you may briefly state your intent (e.g. \"Let me check that\"), but NEVER predict or describe the expected result before receiving it.\n",
    "- Before modifying a file, read it first to confirm its current content.\n",
    "- Do not assume a file or directory exists â€” use list_dir or read_file to verify.\n",
    "- After writing or editing a file, re-read it if accuracy matters.\n",
    "- If a tool call fails, analyze the error before retrying with a different approach.\n",
    "\n",
    "## Memory\n",
    "- Remember important facts: write to {workspace_path}/memory/MEMORY.md\n",
    "- Recall past events: grep {workspace_path}/memory/HISTORY.md\"\"\"\n",
    "    \n",
    "    def _load_bootstrap_files(self) -> str:\n",
    "        \"\"\"Load all bootstrap files from workspace.\"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        for filename in self.BOOTSTRAP_FILES:\n",
    "            file_path = self.workspace / filename\n",
    "            if file_path.exists():\n",
    "                content = file_path.read_text(encoding=\"utf-8\")\n",
    "                parts.append(f\"## {filename}\\n\\n{content}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(parts) if parts else \"\"\n",
    "    \n",
    "    def build_messages(\n",
    "        self,\n",
    "        history: list[dict[str, Any]],\n",
    "        current_message: str,\n",
    "        skill_names: list[str] | None = None,\n",
    "        media: list[str] | None = None,\n",
    "        channel: str | None = None,\n",
    "        chat_id: str | None = None,\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Build the complete message list for an LLM call.\n",
    "\n",
    "        Args:\n",
    "            history: Previous conversation messages.\n",
    "            current_message: The new user message.\n",
    "            skill_names: Optional skills to include.\n",
    "            media: Optional list of local file paths for images/media.\n",
    "            channel: Current channel (telegram, feishu, etc.).\n",
    "            chat_id: Current chat/user ID.\n",
    "\n",
    "        Returns:\n",
    "            List of messages including system prompt.\n",
    "        \"\"\"\n",
    "        messages = []\n",
    "\n",
    "        # System prompt\n",
    "        system_prompt = self.build_system_prompt(skill_names)\n",
    "        if channel and chat_id:\n",
    "            system_prompt += f\"\\n\\n## Current Session\\nChannel: {channel}\\nChat ID: {chat_id}\"\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "        # History\n",
    "        messages.extend(history)\n",
    "\n",
    "        # Current message (with optional image attachments)\n",
    "        user_content = self._build_user_content(current_message, media)\n",
    "        messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "        \n",
    "        \n",
    "        return messages\n",
    "\n",
    "    def _build_user_content(self, text: str, media: list[str] | None) -> str | list[dict[str, Any]]:\n",
    "        \"\"\"Build user message content with optional base64-encoded images.\"\"\"\n",
    "        if not media:\n",
    "            return text\n",
    "        \n",
    "        images = []\n",
    "        for path in media:\n",
    "            p = Path(path)\n",
    "            mime, _ = mimetypes.guess_type(path)\n",
    "            if not p.is_file() or not mime or not mime.startswith(\"image/\"):\n",
    "                continue\n",
    "            b64 = base64.b64encode(p.read_bytes()).decode()\n",
    "            images.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime};base64,{b64}\"}})\n",
    "        \n",
    "        if not images:\n",
    "            return text\n",
    "        return images + [{\"type\": \"text\", \"text\": text}]\n",
    "    \n",
    "    def add_tool_result(\n",
    "        self,\n",
    "        messages: list[dict[str, Any]],\n",
    "        tool_call_id: str,\n",
    "        tool_name: str,\n",
    "        result: str\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Add a tool result to the message list.\n",
    "        \n",
    "        Args:\n",
    "            messages: Current message list.\n",
    "            tool_call_id: ID of the tool call.\n",
    "            tool_name: Name of the tool.\n",
    "            result: Tool execution result.\n",
    "        \n",
    "        Returns:\n",
    "            Updated message list.\n",
    "        \"\"\"\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "            \"name\": tool_name,\n",
    "            \"content\": result\n",
    "        })\n",
    "        return messages\n",
    "    \n",
    "    def add_assistant_message(\n",
    "        self,\n",
    "        messages: list[dict[str, Any]],\n",
    "        content: str | None,\n",
    "        tool_calls: list[dict[str, Any]] | None = None,\n",
    "        reasoning_content: str | None = None,\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Add an assistant message to the message list.\n",
    "        \n",
    "        Args:\n",
    "            messages: Current message list.\n",
    "            content: Message content.\n",
    "            tool_calls: Optional tool calls.\n",
    "            reasoning_content: Thinking output (Kimi, DeepSeek-R1, etc.).\n",
    "        \n",
    "        Returns:\n",
    "            Updated message list.\n",
    "        \"\"\"\n",
    "        msg: dict[str, Any] = {\"role\": \"assistant\"}\n",
    "\n",
    "        # Always include content â€” some providers (e.g. StepFun) reject\n",
    "        # assistant messages that omit the key entirely.\n",
    "        msg[\"content\"] = content\n",
    "\n",
    "        if tool_calls:\n",
    "            msg[\"tool_calls\"] = tool_calls\n",
    "\n",
    "        # Include reasoning content when provided (required by some thinking models)\n",
    "        if reasoning_content is not None:\n",
    "            msg[\"reasoning_content\"] = reasoning_content\n",
    "\n",
    "        messages.append(msg)\n",
    "        return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f36003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
